{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb7he5-r3aHi",
        "outputId": "a0354e08-f86d-4ba0-a00e-5c26df46b828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'dollar-street-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/dollar-street-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"humansintheloop/dollar-street-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r \"/kaggle/input/dollar-street-dataset/Dollar street trial\" \"/content\"\n"
      ],
      "metadata": {
        "id": "_CE2i3CB6rfE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/Dollar street trial\" -type d -name \"Abstract_*\" -exec rm -rf {} +\n"
      ],
      "metadata": {
        "id": "IQSD-m846hc4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/dataset/ann\"\n",
        "!mkdir -p \"/content/dataset/img\"\n"
      ],
      "metadata": {
        "id": "2nwzcIi1FfiU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/Dollar street trial\" -type f -path \"*/ann/*.json\" -exec mv {} \"/content/dataset/ann/\" \\;\n"
      ],
      "metadata": {
        "id": "QpRzMECZF3xL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/Dollar street trial\" -type f -path \"*/img/*\" -exec mv {} /content/dataset/img/ \\;\n"
      ],
      "metadata": {
        "id": "xZtmkn84GTKb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "base = \"/content/dataset\"\n",
        "img_dir = f\"{base}/img\"\n",
        "ann_dir = f\"{base}/ann\"\n",
        "\n",
        "# Create YOLO folders\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    os.makedirs(f\"{base}/images/{split}\", exist_ok=True)\n",
        "    os.makedirs(f\"{base}/labels/{split}\", exist_ok=True)\n",
        "\n",
        "# List all images\n",
        "images = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
        "random.shuffle(images)\n",
        "\n",
        "# 80/10/10 split\n",
        "n = len(images)\n",
        "train_split = int(0.8 * n)\n",
        "val_split = int(0.1 * n)\n",
        "\n",
        "train_files = images[:train_split]\n",
        "val_files = images[train_split:train_split + val_split]\n",
        "test_files = images[train_split + val_split:]\n",
        "\n",
        "def move_files(file_list, split):\n",
        "    for img_file in file_list:\n",
        "        img_path = os.path.join(img_dir, img_file)\n",
        "\n",
        "        # JSON annotation must have same filename\n",
        "        ann_file = img_file+ \".json\"\n",
        "        ann_path = os.path.join(ann_dir, ann_file)\n",
        "\n",
        "        # Copy images\n",
        "        shutil.copy(img_path, f\"{base}/images/{split}/{img_file}\")\n",
        "\n",
        "        # Copy labels (skip if missing)\n",
        "        if os.path.exists(ann_path):\n",
        "            shutil.copy(ann_path, f\"{base}/labels/{split}/{ann_file}\")\n",
        "\n",
        "move_files(train_files, \"train\")\n",
        "move_files(val_files, \"val\")\n",
        "move_files(test_files, \"test\")\n",
        "\n",
        "print(\"Dataset successfully split!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y5A-FtPH8Lm",
        "outputId": "401ab736-7510-4643-9c7b-710d386d53e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully split!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 \"/content/dataset/images/train\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Biiz_4_7K_Xd",
        "outputId": "830cafaf-9178-4b69-c20e-703bf2906fb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 \"/content/dataset/labels/val\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSbGcN2QLARv",
        "outputId": "b55f4618-8c18-43ff-d2c1-1eb03b996b88"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 \"/content/dataset/labels/test\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naxtvJMSJZik",
        "outputId": "ad144371-5b21-4ce9-b301-466565dc082b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import yaml  # PyYAML (already installed in Colab)\n",
        "\n",
        "base_path = \"/content/dataset\"\n",
        "ann_dir = f\"{base_path}/ann\"\n",
        "\n",
        "# 1. Collect all class names\n",
        "class_names = set()\n",
        "\n",
        "for file in os.listdir(ann_dir):\n",
        "    if file.endswith(\".json\"):\n",
        "        with open(os.path.join(ann_dir, file), \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        objects = data.get(\"objects\", [])\n",
        "        for obj in objects:\n",
        "            if \"classTitle\" in obj:\n",
        "                class_names.add(obj[\"classTitle\"])\n",
        "\n",
        "class_names = sorted(list(class_names))\n",
        "\n",
        "print(\"Found classes:\", class_names)\n",
        "\n",
        "# 2. Build YAML structure\n",
        "dataset_yaml = {\n",
        "    \"path\": base_path,\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"test\": \"images/test\",\n",
        "    \"names\": {i: name for i, name in enumerate(class_names)}\n",
        "}\n",
        "\n",
        "# 3. Save YAML file\n",
        "save_path = f\"{base_path}/dataset.yaml\"\n",
        "\n",
        "with open(save_path, \"w\") as f:\n",
        "    yaml.dump(dataset_yaml, f, sort_keys=False)\n",
        "\n",
        "print(f\"dataset.yaml created at: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dbjoUl_Lg2Y",
        "outputId": "4e6eb788-a1bd-4cd4-a81e-2c5aecade80a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found classes: ['Alcoholic drink', 'Armchair', 'Bathroom door', 'Bed', 'Bike', 'Book', 'Bowl', 'Car', 'Car key', 'Chicken', 'Cleaning equipment', 'Cleaning floor', 'Computer', 'Cooking pot', 'Cooking utensils', 'Cup', 'Cutlery', 'Diaper', 'Dish brush', 'Dish rack', 'Dish washing soap', 'Dishwasher', 'Earings', 'Family snapshot', 'Freezers', 'Front door', 'Frontdoor keys', 'Fruit trees', 'Fruits', 'Glasses', 'Goat', 'Grains', 'Guest beds', 'Hair brush', 'Hand', 'Home', 'Instrument', 'Jacket', 'Jewelry', 'Kids bed', 'Kitchen sink', 'Light sources', 'Light sources by bed, reading light', 'Light sources in living room', 'Light sources kitchen', 'Lock on front door', 'Make up', 'Meat', 'Medication', 'Menstruation pads', 'Mosquito protections', 'Motorcycle', 'Music equipment', 'Necklace', 'Oven', 'Palms', 'Paper', 'Pen', 'Pet', 'Pet food', 'Phone', 'Plate', 'Plates of food', 'Power outlet', 'Power switch', 'Radio', 'Refrigerator', 'Roof', 'Rug', 'Salt', 'Shampoo', 'Shoe', 'Shower', 'Soap', 'Social drinks', 'Sofa', 'Spices', 'Stove', 'TV', 'Teeth', 'Toilet', 'Toilet paper', 'Tools', 'Toothbrush', 'Toothpaste', 'Toy', 'Trash', 'Vegetable', 'Wall clock', 'Wardrobe', 'Washing detergent', 'Water outlet', 'Wheel barrow', 'Wrist watch']\n",
            "dataset.yaml created at: /content/dataset/dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "yaml_path = \"/content/dataset/dataset.yaml\"\n",
        "\n",
        "with open(yaml_path, \"r\") as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "# 'names' is a dictionary: {0: 'class1', 1: 'class2', ...}\n",
        "num_classes = len(data.get(\"names\", {}))\n",
        "print(\"Number of classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnYbLVssOOtY",
        "outputId": "3157440d-37b5-461e-c13a-89b33f27169c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZx-WBNdOa5B",
        "outputId": "406d6efd-4164-45f4-eb1f-f6cece8f9e64"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.237-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.237-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.237 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "base_path = \"/content/dataset\"\n",
        "image_dir = f\"{base_path}/images\"\n",
        "label_dir = f\"{base_path}/labels\"\n",
        "\n",
        "# Load class mapping from dataset.yaml\n",
        "import yaml\n",
        "with open(f\"{base_path}/dataset.yaml\") as f:\n",
        "    data_yaml = yaml.safe_load(f)\n",
        "\n",
        "class_mapping = data_yaml[\"names\"]  # {0: 'Plates of food', 1: 'Chair', ...}\n",
        "class_name_to_id = {v: k for k, v in class_mapping.items()}\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    img_split_dir = os.path.join(image_dir, split)\n",
        "    lbl_split_dir = os.path.join(label_dir, split)\n",
        "    os.makedirs(lbl_split_dir, exist_ok=True)\n",
        "\n",
        "    for img_file in os.listdir(img_split_dir):\n",
        "        if not img_file.endswith(\".jpg\"):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(img_split_dir, img_file)\n",
        "        ann_file = os.path.join(base_path, \"ann\", img_file + \".json\")\n",
        "\n",
        "        if not os.path.exists(ann_file):\n",
        "            continue\n",
        "\n",
        "        with open(ann_file) as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        h = data[\"size\"][\"height\"]\n",
        "        w = data[\"size\"][\"width\"]\n",
        "\n",
        "        lines = []\n",
        "        for obj in data.get(\"objects\", []):\n",
        "            class_name = obj[\"classTitle\"]\n",
        "            class_id = class_name_to_id[class_name]\n",
        "\n",
        "            x1, y1 = obj[\"points\"][\"exterior\"][0]\n",
        "            x2, y2 = obj[\"points\"][\"exterior\"][1]\n",
        "\n",
        "            # YOLO normalized format\n",
        "            x_center = ((x1 + x2) / 2) / w\n",
        "            y_center = ((y1 + y2) / 2) / h\n",
        "            width = (x2 - x1) / w\n",
        "            height = (y2 - y1) / h\n",
        "\n",
        "            lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "        # Save TXT label\n",
        "        txt_path = os.path.join(lbl_split_dir, img_file.replace(\".jpg\", \".txt\"))\n",
        "        with open(txt_path, \"w\") as f:\n",
        "            f.write(\"\\n\".join(lines))\n"
      ],
      "metadata": {
        "id": "AhqLqlksPnKP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8s model\n",
        "model = YOLO('yolov8s.yaml')\n",
        "\n",
        "# Train the model\n",
        "model.train(data='/content/dataset/dataset.yaml', epochs=50, imgsz=640, batch=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D9qb76lOUOi",
        "outputId": "cb3ace4c-912f-44e9-f6d5-1e717cd9f87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.237 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=94\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2152426  ultralytics.nn.modules.head.Detect           [94, [128, 256, 512]]         \n",
            "YOLOv8s summary: 129 layers, 11,171,978 parameters, 11,171,962 gradients, 28.8 GFLOPs\n",
            "\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1067.2Â±731.7 MB/s, size: 126.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 18160 images, 4821 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18160/18160 22.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/dataset/images/train/972cd7229df39644a308af74f357eb8ae3cb0849.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/dataset/images/train/ca3a1843ab3c2f892135f79f2b542e6af79867d9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/dataset/images/train/efd02395d5c8ee1698f54c131c715276bf8affa3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 42.6Â±14.6 MB/s, size: 111.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 2270 images, 614 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2270/2270 1.9Mit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      14.5G      3.256      6.129      4.157        160        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 284/284 1.8s/it 8:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 1.6s/it 29.2s\n",
            "                   all       2270       2924   4.09e-05    0.00985   2.74e-05   7.26e-06\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      14.3G      2.477      5.631      3.148        127        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 284/284 1.7s/it 8:12\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 2.0s/it 35.7s\n",
            "                   all       2270       2924    0.00249      0.189    0.00395     0.0013\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      14.2G      1.811       4.89      2.357        146        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 284/284 1.7s/it 7:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 1.7s/it 30.6s\n",
            "                   all       2270       2924      0.344     0.0455     0.0109    0.00506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      14.2G       1.64      4.394      2.114        113        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 284/284 1.7s/it 7:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 1.8s/it 32.8s\n",
            "                   all       2270       2924      0.367       0.08     0.0262     0.0137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      14.2G      1.549      4.032      2.004        147        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 284/284 1.7s/it 8:08\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 1.7s/it 30.1s\n",
            "                   all       2270       2924      0.456      0.102     0.0474     0.0267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      13.5G      1.631      4.126      2.079        190        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/284  1.6s"
          ]
        }
      ]
    }
  ]
}