{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cf4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned on VAL (FAR<=5%)\n",
      "{'th': 61.5, 'open_macro_f1': 0.9045024655168937, 'far': 0.043478260869565216}\n",
      "\n",
      "TEST results @ tuned threshold\n",
      "  threshold: 61.5\n",
      "  FAR: 0.0\n",
      "  TPR_known: 0.9259259259259259\n",
      "  open_acc: 0.9342723004694836\n",
      "  open_macro_f1: 0.9459997290403167\n",
      "  bin_acc: 0.9342723004694836\n",
      "  bin_macro_f1: 0.8678660049627791\n",
      "  bin_roc_auc: 0.9880952380952381\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def _emb_cols(df, prefix=\"e\"):\n",
    "    cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "    return sorted(cols, key=lambda c: int(c[len(prefix):]))\n",
    "\n",
    "def _l2(x, eps=1e-12):\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return x / np.clip(n, eps, None)\n",
    "\n",
    "def _sim_percent_from_dist(d):\n",
    "    # L2-normalized embeddings => Euclidean distance in ~[0,2]\n",
    "    return 100.0 * np.maximum(0.0, 1.0 - (d / 2.0))\n",
    "\n",
    "def _fit_prototypes(train_csv, prefix=\"e\", label_col=\"folder_name\"):\n",
    "    tr = pd.read_csv(train_csv)\n",
    "    cols = _emb_cols(tr, prefix)\n",
    "    Xtr = _l2(tr[cols].to_numpy(dtype=np.float32))\n",
    "    ytr = tr[label_col].astype(str).to_numpy()\n",
    "\n",
    "    names = np.unique(ytr)\n",
    "    P = np.stack([Xtr[ytr == n].mean(axis=0) for n in names], axis=0)\n",
    "    P = _l2(P)\n",
    "    return cols, names, P\n",
    "\n",
    "def _predict_scores(csv_path, cols, names, P, prefix=\"e\", label_col=\"folder_name\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    X = _l2(df[cols].to_numpy(dtype=np.float32))\n",
    "    y = df[label_col].astype(str).to_numpy()\n",
    "\n",
    "    dists = np.linalg.norm(X[:, None, :] - P[None, :, :], axis=2)  # (N,K)\n",
    "    best_k = np.argmin(dists, axis=1)\n",
    "    best_d = dists[np.arange(len(X)), best_k]\n",
    "    best_name = names[best_k]\n",
    "    best_sim = _sim_percent_from_dist(best_d)\n",
    "    return y, best_name, best_sim\n",
    "\n",
    "def tune_threshold_for_far(val_str_csv, cols, names, P, far_max=0.05, grid=np.linspace(0,100,201)):\n",
    "    # FAR = fraction of strangers accepted as known (sim >= th)\n",
    "    _, _, sim = _predict_scores(val_str_csv, cols, names, P)\n",
    "    best_th = None\n",
    "    for th in grid:\n",
    "        far = float((sim >= th).mean())\n",
    "        if far <= far_max:\n",
    "            best_th = float(th)\n",
    "            break\n",
    "    return best_th  # highest threshold isn't what we want; we want smallest th that meets FAR? (see below)\n",
    "\n",
    "def tune_threshold_max_open_macro_f1(val_known_csv, val_str_csv, cols, names, P, far_max=0.05, grid=np.linspace(0,100,201)):\n",
    "    yk, pk, sk = _predict_scores(val_known_csv, cols, names, P)\n",
    "    ys, ps, ss = _predict_scores(val_str_csv, cols, names, P)\n",
    "\n",
    "    best = {\"th\": None, \"open_macro_f1\": -1, \"far\": None}\n",
    "    for th in grid:\n",
    "        far = float((ss >= th).mean())\n",
    "        if far > far_max:\n",
    "            continue\n",
    "\n",
    "        pred_known = np.where(sk >= th, pk, \"Stranger\")\n",
    "        pred_str   = np.where(ss >= th, ps, \"Stranger\")\n",
    "\n",
    "        y_true = np.concatenate([yk, np.array([\"Stranger\"] * len(ys))])\n",
    "        y_pred = np.concatenate([pred_known, pred_str])\n",
    "\n",
    "        score = float(f1_score(y_true, y_pred, average=\"macro\"))\n",
    "        if score > best[\"open_macro_f1\"]:\n",
    "            best = {\"th\": float(th), \"open_macro_f1\": score, \"far\": far}\n",
    "\n",
    "    return best  # contains tuned threshold + score + FAR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score  # + roc_auc_score\n",
    "\n",
    "# ... (everything above unchanged)\n",
    "\n",
    "def eval_with_threshold(test_known_csv, test_str_csv, cols, names, P, th):\n",
    "    yk, pk, sk = _predict_scores(test_known_csv, cols, names, P)\n",
    "    ys, ps, ss = _predict_scores(test_str_csv, cols, names, P)\n",
    "\n",
    "    # open-set macro-F1 (IDs + Stranger)\n",
    "    pred_known = np.where(sk >= th, pk, \"Stranger\")\n",
    "    pred_str   = np.where(ss >= th, ps, \"Stranger\")\n",
    "\n",
    "    y_true_open = np.concatenate([yk, np.array([\"Stranger\"] * len(ys))])\n",
    "    y_pred_open = np.concatenate([pred_known, pred_str])\n",
    "\n",
    "    open_macro_f1 = float(f1_score(y_true_open, y_pred_open, average=\"macro\"))\n",
    "    open_acc = float(accuracy_score(y_true_open, y_pred_open))\n",
    "\n",
    "    # binary known-vs-unknown (thresholded for acc/F1, continuous for ROC AUC)\n",
    "    y_true_bin = np.concatenate([np.ones(len(yk)), np.zeros(len(ys))]).astype(int)\n",
    "    y_pred_bin = np.concatenate([(sk >= th).astype(int), (ss >= th).astype(int)])\n",
    "    bin_acc = float(accuracy_score(y_true_bin, y_pred_bin))\n",
    "    bin_macro_f1 = float(f1_score(y_true_bin, y_pred_bin, average=\"macro\"))\n",
    "\n",
    "    # --- NEW: ROC AUC using raw similarity scores as the positive (known) score\n",
    "    y_scores_bin = np.concatenate([sk, ss])  # higher => more likely known\n",
    "    bin_roc_auc = float(roc_auc_score(y_true_bin, y_scores_bin))\n",
    "\n",
    "    far = float((ss >= th).mean())\n",
    "    tpr_known = float((sk >= th).mean())\n",
    "\n",
    "    return {\n",
    "        \"threshold\": float(th),\n",
    "        \"FAR\": far,\n",
    "        \"TPR_known\": tpr_known,\n",
    "        \"open_acc\": open_acc,\n",
    "        \"open_macro_f1\": open_macro_f1,\n",
    "        \"bin_acc\": bin_acc,\n",
    "        \"bin_macro_f1\": bin_macro_f1,\n",
    "        \"bin_roc_auc\": bin_roc_auc,   # <-- added to results\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Usage\n",
    "# -------------------------\n",
    "TRAIN = \"emb_csv/train_embeddings.csv\"\n",
    "VAL   = \"emb_csv/val_embeddings.csv\"\n",
    "TEST  = \"emb_csv/test_embeddings.csv\"\n",
    "VAL_STR  = \"emb_csv/val_strangers_embeddings.csv\"   # make this split beforehand\n",
    "TEST_STR = \"emb_csv/test_strangers_embeddings.csv\"\n",
    "\n",
    "cols, names, P = _fit_prototypes(TRAIN)\n",
    "\n",
    "best = tune_threshold_max_open_macro_f1(\n",
    "    val_known_csv=VAL,\n",
    "    val_str_csv=VAL_STR,\n",
    "    cols=cols, names=names, P=P,\n",
    "    far_max=0.05,\n",
    "    grid=np.linspace(0, 100, 201)\n",
    ")\n",
    "print(\"Tuned on VAL (FAR<=5%)\")\n",
    "print(best)\n",
    "\n",
    "res = eval_with_threshold(TEST, TEST_STR, cols, names, P, th=best[\"th\"])\n",
    "print(\"\\nTEST results @ tuned threshold\")\n",
    "for k,v in res.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c41e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face.venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
